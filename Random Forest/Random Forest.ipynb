{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédire si un député va voter ou non \n",
    "### Utilisation d'une Random Forest avec comme target la variable 'Présence' (ie. député présent au vote ou non), les features utilisées seront des données sur le profil des députés\n",
    "\n",
    "On choisit de découper la base selon les grands thèmes des scrutins, on pourra ainsi prédire si pour un thème donné les députés votent ou non (une random forest par thème)\n",
    "On s'entraine donc sur un thème et on choisira quelques thèmes à étudier à la fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la variable 'Présence' pour chaque député sur chaque scrutin (base entière)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_votants = pd.read_csv('database_deputes.csv', index_col=0)\n",
    "df_votes2 = pd.read_csv('database_votes2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votes = df_votes2[['idScrutin', 'idVotant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = df_votes2.copy()\n",
    "copy = copy.pivot(index = 'idVotant', columns = 'idScrutin', values = 'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on remplace les NaN par de l'abstention (en confondant abstention et non-votant)\n",
    "copy = copy.fillna('0')\n",
    "\n",
    "copy = copy.replace(['Pour'],'1')\n",
    "copy = copy.replace(['Contre'],'1')\n",
    "copy = copy.replace(['Non-votant'],'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2=copy.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2 = copy2.reset_index()\n",
    "copy2 = copy2.rename(columns = {0 : 'présence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2 = copy2.sort_values(['idScrutin', 'idVotant'])\n",
    "copy2.to_csv('présence.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On merge la variable Présence sur la base complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjr = df_votes2.merge(copy2, on = ['idScrutin', 'idVotant'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices = pd.read_csv('indices_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complet = df_indices.merge(bjr[['idScrutin','idVotant','présence']], on='idVotant', how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrutins2 = df_votes2.drop_duplicates('idScrutin')[['idScrutin','titre','demandeur','date_scrutin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complet=df_complet.merge(df_scrutins2, on = 'idScrutin', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clara\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (25,26,27,28,40,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_cluster = pd.read_csv('df_randomforest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133                ['lutter', 'haine', 'internet']\n",
       "159                ['lutter', 'haine', 'internet']\n",
       "169       ['dumas', 'lutter', 'haine', 'internet']\n",
       "183                ['lutter', 'haine', 'internet']\n",
       "564                  ['fur', 'lutter', 'internet']\n",
       "                            ...                   \n",
       "289479             ['lutter', 'haine', 'internet']\n",
       "289598            ['lutter', 'texte', 'paritaire']\n",
       "289720             ['lutter', 'haine', 'internet']\n",
       "289889             ['lutter', 'haine', 'internet']\n",
       "290172                      ['lutter', 'deuxieme']\n",
       "Name: intitule, Length: 1958, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster[df_cluster['cluster']==29].intitule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster=df_cluster[['idScrutin','cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster=df_cluster.drop_duplicates(['idScrutin','cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complet = df_complet.merge(df_cluster, on =['idScrutin'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  On a le df complet avec les infos nécessaires sur les votants (id, pour, contre, abstention, accord, région, age, genre, parti) et sur les scrutins (thème, date) ainsi que la variable présence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_complet.to_csv('df_rf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On ne garde maintenant que les scrutins proposés après le 01-01-2020 afin de prédire sur cette période "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = df_complet[df_complet['date_scrutin']>\"2019-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = df_prediction[['idVotant','présence','Contre','Pour','indice_accord','taux_abstention','Région_x','age','Genre','CSP','Groupe politique (complet)','idScrutin','date_scrutin','cluster']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous choisissons sur quel cluster (ie, thème) travailler en ne gardant que les scrutins correspondant à ce thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randomforest_19=df_prediction[df_prediction['cluster']==29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randomforest_19_présence=df_randomforest_19['présence'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features finales : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idVotant', 'présence', 'Contre', 'Pour', 'indice_accord',\n",
       "       'taux_abstention', 'Région_x', 'age', 'Genre', 'CSP',\n",
       "       'Groupe politique (complet)', 'idScrutin', 'date_scrutin', 'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_randomforest_19.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Séparation entre features et target :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randomforest_19_présence=df_randomforest_19_présence.astype(int)\n",
    "df_randomforest_19=df_randomforest_19.drop(['présence','idVotant','date_scrutin','idScrutin'], axis =1)\n",
    "#df_randomforest_19=df_randomforest_19.drop('Groupe politique (complet)', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randomforest_19_dummies=pd.get_dummies(df_randomforest_19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_19 = df_randomforest_19_présence['présence']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(df_randomforest_19_dummies, label_19, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les données de la variable Présence sont déséquilibrées (plus de 0 que de 1), on les réequilibre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    365\n",
      "0    365\n",
      "Name: présence, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample,shuffle\n",
    "test_label_counts = test_labels.value_counts()\n",
    "test_features_absent = test_features[test_labels==0]\n",
    "test_labels_absent = test_labels[test_labels==0]\n",
    "features_test_less, labels_test_less = resample(test_features_absent,test_labels_absent,n_samples=test_label_counts[1],replace=False)\n",
    "features_test_ = pd.concat([features_test_less,test_features[test_labels==1]])\n",
    "labels_test_ = pd.concat([labels_test_less,test_labels[test_labels==1]])\n",
    "test_features_, test_labels_ = shuffle(features_test_,labels_test_)\n",
    "print(test_labels_.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1227\n",
      "0    1227\n",
      "Name: présence, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_label_counts = train_labels.value_counts()\n",
    "train_features_absent = (train_features[train_labels==0])\n",
    "train_labels_absent = (train_labels[train_labels==0])\n",
    "features_train_less, labels_train_less = resample(train_features_absent,train_labels_absent,n_samples=train_label_counts[1],replace=False)\n",
    "features_train_ = pd.concat([features_train_less,train_features[train_labels==1]])\n",
    "labels_train_ = pd.concat([labels_train_less,train_labels[train_labels==1]])\n",
    "train_features_, train_labels_ = shuffle(features_train_,labels_train_)\n",
    "print(train_labels_.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On fait tourner la RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 500 , max_depth=10)\n",
    "\n",
    "rf.fit(train_features_, train_labels_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramètre sélectionné: {'max_depth': 8, 'n_estimators': 1000}\n",
      "Score d'apprentissage:  0.6854115729421353\n",
      "Score de test:  0.6328767123287671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':[5,6,7,8,10], 'n_estimators' : [100,200,300,500,1000]}\n",
    "predictor= GridSearchCV(RandomForestClassifier(random_state=0),param_grid=param_grid)\n",
    "predictor.fit(train_features_,train_labels_)\n",
    "print('Paramètre sélectionné:',predictor.best_params_)\n",
    "print('Score d\\'apprentissage: ',predictor.score(train_features_,train_labels_))\n",
    "print('Score de test: ',predictor.score(test_features_,test_labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = rf.predict(test_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score d'apprentissage:  0.7033414832925835\n",
      "Score de test:  0.6205479452054794\n"
     ]
    }
   ],
   "source": [
    "print('Score d\\'apprentissage: ',rf.score(train_features_,train_labels_))\n",
    "print('Score de test: ',rf.score(test_features_,test_labels_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Feature ranking:\")\n",
    "for i, data_class in enumerate(df_randomforest_19_dummies.columns):\n",
    "    print(\"{}. {} ({})\".format(i + 1, data_class, importances[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du recall pour Random Forest\n",
    "\n",
    "recall = recall_score(test_labels_, predictions_test, average='macro')\n",
    "print('Recall: %.3f' % recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du F1-Score pour Random Forest\n",
    "\n",
    "f1 = f1_score(test_labels_, predictions_test, average='macro')\n",
    "print('F1-Score: %.3f' % f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On fait tourner en enlevant une variable a chaque fois pour voir la différence avec l'accuracy normale (ie. avec toutes les variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contre\n",
      "Score d'apprentissage de:  0.7067348678601876\n",
      "Score de test:  0.6336515513126492\n",
      "Pour\n",
      "Score d'apprentissage de:  0.709717607973422\n",
      "Score de test:  0.6237113402061856\n",
      "indice_accord\n",
      "Score d'apprentissage de:  0.694777397260274\n",
      "Score de test:  0.6143867924528302\n",
      "taux_abstention\n",
      "Score d'apprentissage de:  0.6902581182348043\n",
      "Score de test:  0.6035805626598465\n",
      "Région_x\n",
      "Score d'apprentissage de:  0.6989112227805695\n",
      "Score de test:  0.6545226130653267\n",
      "age\n",
      "Score d'apprentissage de:  0.7172818791946308\n",
      "Score de test:  0.63\n",
      "Genre\n",
      "Score d'apprentissage de:  0.7060280759702725\n",
      "Score de test:  0.6299212598425197\n",
      "CSP\n",
      "Score d'apprentissage de:  0.6991666666666667\n",
      "Score de test:  0.6288265306122449\n",
      "Groupe politique (complet)\n",
      "Score d'apprentissage de:  0.6909090909090909\n",
      "Score de test:  0.6047120418848168\n",
      "cluster\n",
      "Score d'apprentissage de:  0.705661948376353\n",
      "Score de test:  0.6214833759590793\n"
     ]
    }
   ],
   "source": [
    "for i in df_randomforest_19.columns:\n",
    "    print(i)\n",
    "    df_test = df_randomforest_19.drop([i], axis=1)\n",
    "    df_test_dummies = pd.get_dummies(df_test)\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(df_test_dummies, label_19, test_size = 0.25)\n",
    "    from sklearn.utils import resample,shuffle\n",
    "    test_label_counts = test_labels.value_counts()\n",
    "    test_features_absent = test_features[test_labels==0]\n",
    "    test_labels_absent = test_labels[test_labels==0]\n",
    "    features_test_less, labels_test_less = resample(test_features_absent,test_labels_absent,n_samples=test_label_counts[1],replace=False)\n",
    "    features_test_ = pd.concat([features_test_less,test_features[test_labels==1]])\n",
    "    labels_test_ = pd.concat([labels_test_less,test_labels[test_labels==1]])\n",
    "    test_features_, test_labels_ = shuffle(features_test_,labels_test_)\n",
    "    #print(test_labels_.value_counts())\n",
    "    train_label_counts = train_labels.value_counts()\n",
    "    train_features_absent = (train_features[train_labels==0])\n",
    "    train_labels_absent = (train_labels[train_labels==0])\n",
    "    features_train_less, labels_train_less = resample(train_features_absent,train_labels_absent,n_samples=train_label_counts[1],replace=False)\n",
    "    features_train_ = pd.concat([features_train_less,train_features[train_labels==1]])\n",
    "    labels_train_ = pd.concat([labels_train_less,train_labels[train_labels==1]])\n",
    "    train_features_, train_labels_ = shuffle(features_train_,labels_train_)\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf = RandomForestClassifier(n_estimators = 500 , max_depth=10)\n",
    "    rf.fit(train_features_, train_labels_);\n",
    "    predictions_test = rf.predict(test_features_)\n",
    "    #print(train_labels_.value_counts())\n",
    "    print('Score d\\'apprentissage de: ',rf.score(train_features_,train_labels_))\n",
    "    print('Score de test: ',rf.score(test_features_,test_labels_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
